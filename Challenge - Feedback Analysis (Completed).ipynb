{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create a binary model from data selected\n",
    "def fit_binary_model(data,target):\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(data, target)\n",
    "    pred = bnb.predict(data)\n",
    "    print('Out of {} predictions, {} were misclassified giving {}% accuracy'.format(data.shape[0], (pred != target).sum(), round((100-((pred != target).sum()/data.shape[0])*100),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']\n",
    "\n",
    "keywords = ['excellent','perfect','terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail', 'annoying', 'cheap','painful', \n",
    "            'avoid', 'slow', 'pretentious', 'problem', 'embarrassing', 'bored', 'horrible', 'lousy', 'unfortunate', 'boring', 'sucks', \n",
    "            'sucked', 'waste',  'wasting', 'mediocre', 'sloppy','disappoint', 'garbage', 'whine','fantastic', 'whiny', 'plot', 'hate ', 'hated',\n",
    "            'negative', 'nobody', 'flaw', 'script', 'insult', 'torture', ' lack', 'lame', 'ridiculous', 'not', 'unbelievable', 'skip', 'shame', \n",
    "           'not even', 'miss', 'amazing', 'love', 'incredible','terrific', 'best', 'great', 'fun',\n",
    "           'beautiful', 'well done', 'enjoy',  'smart', 'highly', 'impress', 'well',' mess ']\n",
    "\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key), case = False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key), case = False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key), case = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 748 predictions, 151 were misclassified giving 79.8% accuracy\n"
     ]
    }
   ],
   "source": [
    "fit_binary_model(imdb[keywords],imdb['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions, 288 were misclassified giving 71.2% accuracy\n"
     ]
    }
   ],
   "source": [
    "fit_binary_model(yelp[keywords],yelp['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions, 273 were misclassified giving 72.7% accuracy\n"
     ]
    }
   ],
   "source": [
    "fit_binary_model(amazon[keywords],amazon['positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model works the best for imdb emails with a classification accuracy of 79.8% which makes sense since most of the words in the keywords list were taken from the imdb emails.  The other 2 models still perform fairly well giving >70% accuracy for each"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
