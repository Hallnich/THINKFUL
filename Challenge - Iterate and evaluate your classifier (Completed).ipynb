{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1ST ITERATION OF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail']\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key),case=False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key),case=False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key),case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to save space below\n",
    "\n",
    "# Define function to create a binary model from data selected\n",
    "def fit_binary_model(data,target):\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(data[keywords], target)\n",
    "    pred = bnb.predict(data)\n",
    "    print('Out of {} predictions, {} were misclassified giving {}% accuracy'.format(data.shape[0],\n",
    "                                                                                    (pred != target).sum(),\n",
    "                                                                                    round((100-((pred != target).sum() / data.shape[0])*100),1)))\n",
    "# Define function to generate confusion matrix of results generated by model\n",
    "def get_conf_matrix(data,target):\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(data, target)\n",
    "    pred = bnb.predict(data)\n",
    "    matrix = pd.DataFrame(confusion_matrix(target,pred))\n",
    "    matrix.columns=(\"Negative Reviews\",\"Positive Reviews\")\n",
    "    matrix.index = (\"Number Predicted Negative\",\"Number Predicted Positive\")\n",
    "    return matrix\n",
    "\n",
    "# Create function to compare outputs from models after defining new keywords below\n",
    "def compare_models():\n",
    "    # Run model for IMDB Reviews\n",
    "    print('-'*100,)\n",
    "    print(\"FOR THE IMDB DATASET\")\n",
    "    input_df = imdb[keywords]\n",
    "    target_df = imdb['positive']\n",
    "    fit_binary_model(input_df,target_df)\n",
    "    print(get_conf_matrix(input_df,target_df))\n",
    "\n",
    "    # Run model for Yelp Reviews\n",
    "    print('-'*100,)\n",
    "    print(\"FOR THE YELP DATASET\")\n",
    "    input_df = yelp[keywords]\n",
    "    target_df = yelp['positive']\n",
    "    fit_binary_model(input_df,target_df)\n",
    "    print(get_conf_matrix(input_df,target_df))\n",
    "\n",
    "    # Run model for Amazon Reviews\n",
    "    print('-'*100,)\n",
    "    print(\"FOR THE AMAZON DATASET\")\n",
    "    input_df = amazon[keywords]\n",
    "    target_df = amazon['positive']\n",
    "    fit_binary_model(input_df,target_df)\n",
    "    print(get_conf_matrix(input_df,target_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE IMDB DATASET\n",
      "Out of 748 predictions, 268 were misclassified giving 64.2% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               105               257\n",
      "Number Predicted Positive                11               375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE YELP DATASET\n",
      "Out of 1000 predictions, 446 were misclassified giving 55.4% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative                55               445\n",
      "Number Predicted Positive                 1               499\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE AMAZON DATASET\n",
      "Out of 1000 predictions, 434 were misclassified giving 56.6% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative                67               433\n",
      "Number Predicted Positive                 1               499\n"
     ]
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ND ITERATION OF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data again\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail', \n",
    "            'annoying', 'cheap','lousy','torture', 'ridiculous', 'not', 'unbelievable', 'skip', 'shame']\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key),case=False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key),case=False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key),case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE IMDB DATASET\n",
      "Out of 748 predictions, 225 were misclassified giving 69.9% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               164               198\n",
      "Number Predicted Positive                27               359\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE YELP DATASET\n",
      "Out of 1000 predictions, 362 were misclassified giving 63.8% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               161               339\n",
      "Number Predicted Positive                23               477\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE AMAZON DATASET\n",
      "Out of 1000 predictions, 343 were misclassified giving 65.7% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               176               324\n",
      "Number Predicted Positive                19               481\n"
     ]
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3RD ITERATION OF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data again\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail', \n",
    "            'annoying', 'cheap','lousy','torture', 'ridiculous', 'not', 'unbelievable', 'skip', 'shame', \n",
    "            'not even', 'miss', 'terrific', 'best', 'great', 'fun']\n",
    "\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key),case=False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key),case=False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key),case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE IMDB DATASET\n",
      "Out of 748 predictions, 223 were misclassified giving 70.2% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               165               197\n",
      "Number Predicted Positive                26               360\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE YELP DATASET\n",
      "Out of 1000 predictions, 359 were misclassified giving 64.1% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               160               340\n",
      "Number Predicted Positive                19               481\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE AMAZON DATASET\n",
      "Out of 1000 predictions, 343 were misclassified giving 65.7% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               173               327\n",
      "Number Predicted Positive                16               484\n"
     ]
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4TH ITERATION OF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data again\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail', \n",
    "            'annoying', 'cheap','lousy', 'unfortunate', 'boring', 'sucks', 'sucked', 'waste',\n",
    "            'torture', ' lack', 'lame', 'ridiculous', 'not', 'unbelievable', 'skip', 'shame', \n",
    "           'not even', 'miss', 'terrific', 'best', 'great', 'fun']\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key),case=False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key),case=False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key),case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE IMDB DATASET\n",
      "Out of 748 predictions, 202 were misclassified giving 73.0% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               184               178\n",
      "Number Predicted Positive                24               362\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE YELP DATASET\n",
      "Out of 1000 predictions, 340 were misclassified giving 66.0% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               179               321\n",
      "Number Predicted Positive                19               481\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE AMAZON DATASET\n",
      "Out of 1000 predictions, 321 were misclassified giving 67.9% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               195               305\n",
      "Number Predicted Positive                16               484\n"
     ]
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL ITERATION OF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data again\n",
    "imdb = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_imdb.txt',delimiter='\\t',header=None)\n",
    "amazon = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_amazon.txt',delimiter='\\t',header=None)\n",
    "yelp = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\sentiment_detector_model\\data_yelp.txt',delimiter='\\t',header=None)\n",
    "\n",
    "# Change column names to make data uniform\n",
    "imdb.columns = ['review', 'positive']\n",
    "yelp.columns = ['review', 'positive']\n",
    "amazon.columns = ['review', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['terrible', 'awful', 'worst', 'bad', 'stupid', 'poor', 'worse', 'attempt', 'crap', 'fail', 'annoying', 'cheap',\n",
    "           'painful', 'avoid', 'slow', 'pretentious', 'problem', 'embarrassing', 'bored', 'horrible', 'lousy', 'unfortunate', \n",
    "           'boring', 'sucks', 'sucked', 'waste', ' mess ', 'wasting', 'mediocre', 'sloppy',\n",
    "           'disappoint', 'garbage', 'whine', 'whiny', 'plot', 'hate ', 'hated', 'negative', 'nobody', 'flaw',\n",
    "           'script', 'insult', 'do not', 'torture', ' lack', 'lame', 'ridiculous', 'not', 'unbelievable', 'skip', 'shame', \n",
    "           'not even', 'miss', 'excellent', 'amazing', 'love', 'incredible', 'fantastic', 'terrific', 'best', 'great', 'fun']\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(str(key),case=False)\n",
    "    yelp[str(key)] = yelp.review.str.contains(str(key),case=False)\n",
    "    amazon[str(key)] = amazon.review.str.contains(str(key),case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE IMDB DATASET\n",
      "Out of 748 predictions, 158 were misclassified giving 78.9% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               233               129\n",
      "Number Predicted Positive                29               357\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE YELP DATASET\n",
      "Out of 1000 predictions, 291 were misclassified giving 70.9% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               229               271\n",
      "Number Predicted Positive                20               480\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR THE AMAZON DATASET\n",
      "Out of 1000 predictions, 273 were misclassified giving 72.7% accuracy\n",
      "                           Negative Reviews  Positive Reviews\n",
      "Number Predicted Negative               250               250\n",
      "Number Predicted Positive                23               477\n"
     ]
    }
   ],
   "source": [
    "compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
